{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be84bbac-0760-4753-9ac2-138b71e8694a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>AVG_score</th>\n",
       "      <th>Fav_subject_1</th>\n",
       "      <th>Fav_subject_2</th>\n",
       "      <th>Fav_subject_3</th>\n",
       "      <th>Prize</th>\n",
       "      <th>Hobby_1</th>\n",
       "      <th>Hobby_2</th>\n",
       "      <th>Hobby_3</th>\n",
       "      <th>Character</th>\n",
       "      <th>Career_trends_1</th>\n",
       "      <th>Career_trends_2</th>\n",
       "      <th>Career_trends_3</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>VƒÉn</td>\n",
       "      <td>S·ª≠</td>\n",
       "      <td>ƒê·ªãa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vi·∫øt l√°ch</td>\n",
       "      <td>Ch·ª•p ·∫£nh</td>\n",
       "      <td>Xem phim</td>\n",
       "      <td>H∆∞·ªõng ngo·∫°i</td>\n",
       "      <td>S√°ng t·∫°o</td>\n",
       "      <td>·∫¢nh h∆∞·ªüng x√£ h·ªôi</td>\n",
       "      <td>Danh v·ªçng</td>\n",
       "      <td>Truy·ªÅn th√¥ng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Sinh</td>\n",
       "      <td>Ho√°</td>\n",
       "      <td>To√°n</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Nghi√™n c·ª©u</td>\n",
       "      <td>Vi·∫øt l√°ch</td>\n",
       "      <td>T√≠nh nguy·ªán</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>·ªîn ƒë·ªãnh</td>\n",
       "      <td>T·ª± do</td>\n",
       "      <td>C·ªëng hi·∫øn</td>\n",
       "      <td>B√°o ch√≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>7.8</td>\n",
       "      <td>Sinh</td>\n",
       "      <td>ƒê·ªãa</td>\n",
       "      <td>H√≥a</td>\n",
       "      <td>No</td>\n",
       "      <td>L√†m v∆∞·ªùn</td>\n",
       "      <td>N·∫•u ƒÉn</td>\n",
       "      <td>Th·ªß c√¥ng</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>C√¢n b·∫±ng cu·ªôc s·ªëng</td>\n",
       "      <td>C·ªëng hi·∫øn</td>\n",
       "      <td>·ªîn ƒë·ªãnh</td>\n",
       "      <td>N√¥ng nghi·ªáp c√¥ng ngh·ªá cao</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>8.3</td>\n",
       "      <td>Anh</td>\n",
       "      <td>VƒÉn</td>\n",
       "      <td>S·ª≠</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Nghi√™n c·ª©u</td>\n",
       "      <td>Du l·ªãch</td>\n",
       "      <td>Kh·∫£o c·ªï</td>\n",
       "      <td>H∆∞·ªõng ngo·∫°i</td>\n",
       "      <td>T·ª± do</td>\n",
       "      <td>C·ªëng hi·∫øn</td>\n",
       "      <td>Danh v·ªçng</td>\n",
       "      <td>Kh·∫£o c·ªï</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>8.2</td>\n",
       "      <td>Sinh</td>\n",
       "      <td>H√≥a</td>\n",
       "      <td>To√°n</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Nghi√™n c·ª©u</td>\n",
       "      <td>Vi·∫øt l√°ch</td>\n",
       "      <td>T√¨nh nguy·ªán</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>·ªîn ƒë·ªãnh</td>\n",
       "      <td>T·ª± do</td>\n",
       "      <td>C·ªëng hi·∫øn</td>\n",
       "      <td>B√°o ch√≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>596</td>\n",
       "      <td>6.7</td>\n",
       "      <td>H√≥a</td>\n",
       "      <td>Sinh</td>\n",
       "      <td>To√°n</td>\n",
       "      <td>No</td>\n",
       "      <td>Nghi√™n c·ª©u</td>\n",
       "      <td>Th√≠ nghi·ªám</td>\n",
       "      <td>ƒê·ªçc s√°ch</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>Tr√≠ tu·ªá</td>\n",
       "      <td>C·ªëng hi·∫øn</td>\n",
       "      <td>·ªîn ƒë·ªãnh</td>\n",
       "      <td>C√¥ng ngh·ªá sinh h·ªçc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>597</td>\n",
       "      <td>6.8</td>\n",
       "      <td>To√°n</td>\n",
       "      <td>Anh</td>\n",
       "      <td>L√Ω</td>\n",
       "      <td>Yes</td>\n",
       "      <td>L·∫≠p tr√¨nh</td>\n",
       "      <td>Ch∆°i th·ªÉ thao</td>\n",
       "      <td>Ch∆°i nh·∫°c c·ª•</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>C√¥ng ngh·ªá cao</td>\n",
       "      <td>Tr√≠ tu·ªá</td>\n",
       "      <td>L∆∞∆°ng cao</td>\n",
       "      <td>Ph√¢n t√≠ch d·ªØ li·ªáu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>598</td>\n",
       "      <td>6.9</td>\n",
       "      <td>VƒÉn</td>\n",
       "      <td>S·ª≠</td>\n",
       "      <td>Anh</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Vi·∫øt l√°ch</td>\n",
       "      <td>Di·ªÖn k·ªãch</td>\n",
       "      <td>Ch·ª•p ·∫£nh</td>\n",
       "      <td>H∆∞·ªõng ngo·∫°i</td>\n",
       "      <td>·∫¢nh h∆∞·ªüng x√£ h·ªôi</td>\n",
       "      <td>Danh v·ªçng</td>\n",
       "      <td>T·ª± do</td>\n",
       "      <td>Ngh·ªá thu·∫≠t bi·ªÉu di·ªÖn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>599</td>\n",
       "      <td>7.0</td>\n",
       "      <td>To√°n</td>\n",
       "      <td>H√≥a</td>\n",
       "      <td>ƒê·ªãa</td>\n",
       "      <td>Yes</td>\n",
       "      <td>L·∫≠p tr√¨nh</td>\n",
       "      <td>L√†m v∆∞·ªùn</td>\n",
       "      <td>Th·ªß c√¥ng</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>C√¥ng ngh·ªá cao</td>\n",
       "      <td>C·ªëng hi·∫øn</td>\n",
       "      <td>Kh√°m ph√°</td>\n",
       "      <td>K·ªπ thu·∫≠t ƒëi·ªán t·ª≠</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>600</td>\n",
       "      <td>7.1</td>\n",
       "      <td>Sinh</td>\n",
       "      <td>H√≥a</td>\n",
       "      <td>VƒÉn</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Nghi√™n c·ª©u</td>\n",
       "      <td>Vi·∫øt l√°ch</td>\n",
       "      <td>ƒê·ªçc s√°ch</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>C·ªëng hi·∫øn</td>\n",
       "      <td>·ªîn ƒë·ªãnh</td>\n",
       "      <td>An to√†n</td>\n",
       "      <td>D∆∞·ª£c h·ªçc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows √ó 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  AVG_score Fav_subject_1 Fav_subject_2 Fav_subject_3 Prize  \\\n",
       "0      1        8.5           VƒÉn            S·ª≠           ƒê·ªãa   Yes   \n",
       "1      2        8.2          Sinh           Ho√°          To√°n   Yes   \n",
       "2      3        7.8          Sinh           ƒê·ªãa           H√≥a    No   \n",
       "3      4        8.3           Anh           VƒÉn            S·ª≠   Yes   \n",
       "4      5        8.2          Sinh           H√≥a          To√°n   Yes   \n",
       "..   ...        ...           ...           ...           ...   ...   \n",
       "595  596        6.7           H√≥a          Sinh          To√°n    No   \n",
       "596  597        6.8          To√°n           Anh            L√Ω   Yes   \n",
       "597  598        6.9           VƒÉn            S·ª≠           Anh   Yes   \n",
       "598  599        7.0          To√°n           H√≥a           ƒê·ªãa   Yes   \n",
       "599  600        7.1          Sinh           H√≥a           VƒÉn   Yes   \n",
       "\n",
       "        Hobby_1        Hobby_2       Hobby_3    Character     Career_trends_1  \\\n",
       "0     Vi·∫øt l√°ch       Ch·ª•p ·∫£nh      Xem phim  H∆∞·ªõng ngo·∫°i            S√°ng t·∫°o   \n",
       "1    Nghi√™n c·ª©u      Vi·∫øt l√°ch   T√≠nh nguy·ªán    H∆∞·ªõng n·ªôi             ·ªîn ƒë·ªãnh   \n",
       "2      L√†m v∆∞·ªùn         N·∫•u ƒÉn      Th·ªß c√¥ng    H∆∞·ªõng n·ªôi  C√¢n b·∫±ng cu·ªôc s·ªëng   \n",
       "3    Nghi√™n c·ª©u        Du l·ªãch       Kh·∫£o c·ªï  H∆∞·ªõng ngo·∫°i               T·ª± do   \n",
       "4    Nghi√™n c·ª©u      Vi·∫øt l√°ch   T√¨nh nguy·ªán    H∆∞·ªõng n·ªôi             ·ªîn ƒë·ªãnh   \n",
       "..          ...            ...           ...          ...                 ...   \n",
       "595  Nghi√™n c·ª©u     Th√≠ nghi·ªám      ƒê·ªçc s√°ch    H∆∞·ªõng n·ªôi             Tr√≠ tu·ªá   \n",
       "596   L·∫≠p tr√¨nh  Ch∆°i th·ªÉ thao  Ch∆°i nh·∫°c c·ª•    H∆∞·ªõng n·ªôi       C√¥ng ngh·ªá cao   \n",
       "597   Vi·∫øt l√°ch      Di·ªÖn k·ªãch      Ch·ª•p ·∫£nh  H∆∞·ªõng ngo·∫°i    ·∫¢nh h∆∞·ªüng x√£ h·ªôi   \n",
       "598   L·∫≠p tr√¨nh       L√†m v∆∞·ªùn      Th·ªß c√¥ng    H∆∞·ªõng n·ªôi       C√¥ng ngh·ªá cao   \n",
       "599  Nghi√™n c·ª©u      Vi·∫øt l√°ch      ƒê·ªçc s√°ch    H∆∞·ªõng n·ªôi           C·ªëng hi·∫øn   \n",
       "\n",
       "      Career_trends_2 Career_trends_3                      Label  \n",
       "0    ·∫¢nh h∆∞·ªüng x√£ h·ªôi       Danh v·ªçng               Truy·ªÅn th√¥ng  \n",
       "1               T·ª± do       C·ªëng hi·∫øn                    B√°o ch√≠  \n",
       "2           C·ªëng hi·∫øn         ·ªîn ƒë·ªãnh  N√¥ng nghi·ªáp c√¥ng ngh·ªá cao  \n",
       "3           C·ªëng hi·∫øn       Danh v·ªçng                    Kh·∫£o c·ªï  \n",
       "4               T·ª± do       C·ªëng hi·∫øn                    B√°o ch√≠  \n",
       "..                ...             ...                        ...  \n",
       "595         C·ªëng hi·∫øn         ·ªîn ƒë·ªãnh         C√¥ng ngh·ªá sinh h·ªçc  \n",
       "596           Tr√≠ tu·ªá       L∆∞∆°ng cao          Ph√¢n t√≠ch d·ªØ li·ªáu  \n",
       "597         Danh v·ªçng           T·ª± do       Ngh·ªá thu·∫≠t bi·ªÉu di·ªÖn  \n",
       "598         C·ªëng hi·∫øn        Kh√°m ph√°           K·ªπ thu·∫≠t ƒëi·ªán t·ª≠  \n",
       "599           ·ªîn ƒë·ªãnh         An to√†n                   D∆∞·ª£c h·ªçc  \n",
       "\n",
       "[600 rows x 14 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('KQ.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1adf3bce-8d77-4d89-8e3d-7e97a92e2e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     AVG_score  Prize  Character  Anh  Ho√°  H√≥a  L√Ω  Sinh  S·ª≠  To√°n  ...  \\\n",
      "0          8.5      1          0    0    0    0   0     0   1     0  ...   \n",
      "1          8.2      1          1    0    1    0   0     1   0     1  ...   \n",
      "2          7.8      0          1    0    0    1   0     1   0     0  ...   \n",
      "3          8.3      1          0    1    0    0   0     0   1     0  ...   \n",
      "4          8.2      1          1    0    0    1   0     1   0     1  ...   \n",
      "..         ...    ...        ...  ...  ...  ...  ..   ...  ..   ...  ...   \n",
      "595        6.7      0          1    0    0    1   0     1   0     1  ...   \n",
      "596        6.8      1          1    1    0    0   1     0   0     1  ...   \n",
      "597        6.9      1          0    1    0    0   0     0   1     0  ...   \n",
      "598        7.0      1          1    0    0    1   0     0   0     1  ...   \n",
      "599        7.1      1          1    0    0    1   0     1   0     0  ...   \n",
      "\n",
      "     L√†m ch·ªß  L∆∞∆°ng cao  Ph√¢n t√≠ch d·ªØ li·ªáu  Qu·ªëc t·∫ø h√≥a  S√°ng t·∫°o  \\\n",
      "0          0          0                  0            0         1   \n",
      "1          0          0                  0            0         0   \n",
      "2          0          0                  0            0         0   \n",
      "3          0          0                  0            0         0   \n",
      "4          0          0                  0            0         0   \n",
      "..       ...        ...                ...          ...       ...   \n",
      "595        0          0                  0            0         0   \n",
      "596        0          1                  0            0         0   \n",
      "597        0          0                  0            0         0   \n",
      "598        0          0                  0            0         0   \n",
      "599        0          0                  0            0         0   \n",
      "\n",
      "     ThƒÉng ti·∫øn nhanh  Tr√≠ tu·ªá  T·ª± do  ·∫¢nh h∆∞·ªüng x√£ h·ªôi  ·ªîn ƒë·ªãnh  \n",
      "0                   0        0      0                 1        0  \n",
      "1                   0        0      1                 0        1  \n",
      "2                   0        0      0                 0        1  \n",
      "3                   0        0      1                 0        0  \n",
      "4                   0        0      1                 0        1  \n",
      "..                ...      ...    ...               ...      ...  \n",
      "595                 0        1      0                 0        1  \n",
      "596                 0        1      0                 0        0  \n",
      "597                 0        0      1                 1        0  \n",
      "598                 0        0      0                 0        0  \n",
      "599                 0        0      0                 0        1  \n",
      "\n",
      "[600 rows x 51 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "# ------------------------\n",
    "# One Hot Encoding\n",
    "# ------------------------\n",
    "# D√πng sklearn OneHotEncoder\n",
    "\n",
    "# Gom 3 c·ªôt Fav_subject th√†nh m·ªôt list\n",
    "df[\"Fav_subjects\"] = df[[\"Fav_subject_1\", \"Fav_subject_2\", \"Fav_subject_3\"]].values.tolist()\n",
    "\n",
    "# Multi-hot encoding\n",
    "mlb = MultiLabelBinarizer()\n",
    "fav_subject_encoded = pd.DataFrame(\n",
    "    mlb.fit_transform(df[\"Fav_subjects\"]),\n",
    "    columns=mlb.classes_,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df[\"Hobby\"] = df[[\"Hobby_1\", \"Hobby_2\", \"Hobby_3\"]].values.tolist()\n",
    "mlb_hobby = MultiLabelBinarizer()\n",
    "hobby_encoded = pd.DataFrame(\n",
    "    mlb_hobby.fit_transform(df[\"Hobby\"]),\n",
    "    columns=mlb_hobby.classes_,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "df[\"Career_trends\"] = df[[\"Career_trends_1\", \"Career_trends_2\", \"Career_trends_3\"]].values.tolist()\n",
    "\n",
    "mlb_career_trends= MultiLabelBinarizer()\n",
    "career_trends_encoded = pd.DataFrame(\n",
    "    mlb_career_trends.fit_transform(df[\"Career_trends\"]),\n",
    "    columns=mlb_career_trends.classes_,\n",
    "    index=df.index\n",
    ")\n",
    "\n",
    "# Gh√©p v√†o dataframe g·ªëc\n",
    "df_encoded = pd.concat([df[[\"AVG_score\", \"Prize\", \"Character\"]], fav_subject_encoded, hobby_encoded, career_trends_encoded], axis=1)\n",
    "\n",
    "# ------------------------\n",
    "# Label Encoding\n",
    "# ------------------------\n",
    "le_encoder = LabelEncoder()\n",
    "df_encoded[\"Prize\"] = le_encoder.fit_transform(df[\"Prize\"])\n",
    "df_encoded[\"Character\"] = le_encoder.fit_transform(df[\"Character\"])\n",
    "\n",
    "print(df_encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "050fce92-0f85-44ad-8041-84be9b1210d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([61,  0, 48, 22,  0,  7, 38,  0,  7, 28, 61, 48, 17, 12, 60,  8,  7,\n",
       "        7, 12, 61, 48, 38, 17, 67, 10, 26,  8,  0, 65, 61, 49, 34, 12, 60,\n",
       "        8, 67, 60, 26, 12, 61,  8, 67,  7, 49,  0, 17, 38, 10,  8, 12,  7,\n",
       "       61, 37, 48, 34, 12, 26, 26, 12, 61,  8, 67,  7, 48,  0, 17, 38, 10,\n",
       "        8, 12,  7, 61, 37, 49, 34, 12, 60,  8, 67, 17, 61,  7, 12, 61,  8,\n",
       "       67, 65, 33,  1, 52, 19, 17, 33,  1, 52, 19, 65, 56, 53, 74, 64, 26,\n",
       "       34, 63,  6, 58,  9, 18, 48, 38, 65, 70,  1, 17, 24, 69, 34, 17,  2,\n",
       "       21, 52, 36, 25, 43, 71, 24, 33, 45,  3, 18,  6, 67, 14, 76, 17, 42,\n",
       "       34, 33, 62, 74, 24, 15, 65, 67, 19, 13, 26, 48,  1, 17, 52, 70, 39,\n",
       "       18, 23, 19,  9, 56, 33, 43, 17, 36, 23, 61, 70, 51, 26,  1, 20, 18,\n",
       "       42, 19, 21, 63, 74, 65, 17, 33, 62, 52, 17, 36,  1, 50, 68,  9, 31,\n",
       "       38, 45, 65, 42,  6,  7, 33, 51, 18, 74,  1, 50, 23, 56, 16,  7,  1,\n",
       "       73, 41, 67,  7,  1, 73, 41, 16, 67, 29, 46, 40, 18,  1, 72, 30, 66,\n",
       "       54,  7,  1, 75,  5, 17, 56, 33, 52,  6,  1, 50, 45, 63, 18, 68, 23,\n",
       "        1, 17, 74, 65,  9, 34, 52,  6, 17, 38, 70, 31, 52, 63, 18, 36, 26,\n",
       "       42, 50,  6, 34, 52, 65,  1, 17, 11, 25, 52, 27, 44, 24, 47, 17, 57,\n",
       "       68, 52, 33,  1, 17,  1, 52, 36, 50, 56, 68, 23, 63, 33, 11, 65,  1,\n",
       "       74, 17, 59, 42, 34, 63, 18,  1,  6,  9, 20, 50, 57, 24, 33, 63, 65,\n",
       "       70, 38, 25,  1, 74, 17, 52, 33, 23,  6, 17, 57, 34, 35, 68, 65, 63,\n",
       "       18, 43, 25,  1, 33, 52, 20, 17, 56, 68, 42, 50, 63, 47, 34,  0, 24,\n",
       "       65, 59, 74, 26, 42, 18, 52, 34,  1,  6, 50, 63, 68, 25, 38, 17, 70,\n",
       "       35, 34,  0, 74, 18, 63, 33, 52, 11, 65, 57, 34, 42, 70, 17, 63, 26,\n",
       "       24, 65,  1, 56, 33, 52,  6,  1, 50, 45, 63, 18, 68, 23,  1, 17, 74,\n",
       "       65,  9, 34, 52,  6, 17, 38, 70, 31, 52, 63, 18, 36, 26, 42, 50,  6,\n",
       "       34, 52, 65,  1, 17, 11, 25, 52, 17, 43, 32, 19, 23, 17, 56, 55, 43,\n",
       "       65, 65, 56, 33, 52,  6,  1, 17, 45, 65, 63, 68, 34, 52, 57, 25, 74,\n",
       "       52, 33,  9, 18, 38, 11,  4, 23,  6, 63, 17, 36, 50,  1,  7, 56, 33,\n",
       "       52,  6,  1, 50,  9, 68, 17, 57, 70, 34, 42, 63, 65, 45, 26, 38,  6,\n",
       "       50, 56, 52, 17, 11, 65, 52, 45, 17,  1,  6, 52, 68, 25, 56, 36, 50,\n",
       "       38, 18,  9, 33, 63,  1, 56, 33, 52,  6,  1, 50,  9, 68, 17, 57, 70,\n",
       "       34, 42, 63, 65, 45, 26, 38,  6, 50, 56, 52, 17, 11, 65, 52, 45, 17,\n",
       "        1,  6, 52, 68, 25, 56, 36, 50, 38, 18,  9, 33, 63,  7, 17, 11, 38,\n",
       "       25,  9,  6, 17,  1,  1, 36, 52, 33, 38, 68, 17,  9, 45, 25, 56, 52,\n",
       "       77, 36,  1, 18, 59,  6, 17, 35, 74, 63, 34, 68, 52, 38, 18, 36, 50,\n",
       "       17, 56, 33, 52,  6, 38, 50, 36,  1, 18, 68,  9, 26, 52, 45, 25,  1,\n",
       "        6, 50, 38, 34, 11])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_encoded\n",
    "y = le_encoder.fit_transform(df[\"Label\"])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47dc7ef2-cd5e-4781-aca6-eaf00a4b2484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43333333333333335\n",
      "üìä Confusion Matrix:\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 2 0 ... 0 0 0]\n",
      " [0 1 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 1 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "\n",
      "üìà Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       0.29      0.33      0.31         6\n",
      "           2       0.00      0.00      0.00         1\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.00      0.00      0.00         0\n",
      "           6       0.43      0.50      0.46         6\n",
      "           7       1.00      0.33      0.50         3\n",
      "           8       0.50      0.50      0.50         2\n",
      "           9       1.00      0.67      0.80         3\n",
      "          10       1.00      1.00      1.00         1\n",
      "          11       0.50      1.00      0.67         1\n",
      "          12       0.50      0.50      0.50         2\n",
      "          14       0.00      0.00      0.00         1\n",
      "          17       0.57      0.57      0.57         7\n",
      "          18       0.20      0.14      0.17         7\n",
      "          19       1.00      0.33      0.50         3\n",
      "          20       1.00      1.00      1.00         1\n",
      "          23       0.00      0.00      0.00         1\n",
      "          24       0.00      0.00      0.00         3\n",
      "          25       0.33      1.00      0.50         1\n",
      "          26       0.00      0.00      0.00         3\n",
      "          31       1.00      1.00      1.00         1\n",
      "          33       0.25      0.33      0.29         3\n",
      "          34       0.33      0.33      0.33         3\n",
      "          36       0.50      1.00      0.67         2\n",
      "          37       1.00      1.00      1.00         1\n",
      "          38       0.20      0.33      0.25         3\n",
      "          41       1.00      1.00      1.00         1\n",
      "          42       0.33      0.33      0.33         3\n",
      "          43       0.00      0.00      0.00         0\n",
      "          45       0.00      0.00      0.00         0\n",
      "          48       0.50      0.67      0.57         3\n",
      "          49       0.00      0.00      0.00         2\n",
      "          50       0.57      1.00      0.73         4\n",
      "          51       0.00      0.00      0.00         1\n",
      "          52       0.43      0.60      0.50         5\n",
      "          55       0.00      0.00      0.00         1\n",
      "          56       0.00      0.00      0.00         3\n",
      "          57       0.00      0.00      0.00         1\n",
      "          59       0.00      0.00      0.00         1\n",
      "          60       0.50      1.00      0.67         1\n",
      "          61       1.00      0.60      0.75         5\n",
      "          62       0.00      0.00      0.00         0\n",
      "          63       0.50      0.67      0.57         6\n",
      "          65       0.33      0.40      0.36         5\n",
      "          67       0.00      0.00      0.00         2\n",
      "          68       0.33      0.25      0.29         4\n",
      "          70       1.00      0.33      0.50         3\n",
      "          72       0.00      0.00      0.00         1\n",
      "          73       1.00      1.00      1.00         1\n",
      "          74       1.00      1.00      1.00         1\n",
      "          75       0.00      0.00      0.00         0\n",
      "          77       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.43       120\n",
      "   macro avg       0.38      0.39      0.36       120\n",
      "weighted avg       0.44      0.43      0.41       120\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "D:\\Anaconda\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# 4. X·ª≠ l√Ω missing values: N·∫øu c√≥ missing values th√¨ b·∫°n c√≥ th·ªÉ thay th·∫ø b·∫±ng median ho·∫∑c mode\n",
    "# V√≠ d·ª•: N·∫øu c√≥ gi√° tr·ªã missing trong c√°c c·ªôt s·ªë, ta thay th·∫ø b·∫±ng gi√° tr·ªã trung b√¨nh ho·∫∑c trung v·ªã (median)\n",
    "X = X.fillna(X.median())\n",
    "\n",
    "# 5. T√°ch d·ªØ li·ªáu th√†nh t·∫≠p hu·∫•n luy·ªán v√† ki·ªÉm tra\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Kh·ªüi t·∫°o m√¥ h√¨nh Random Forest\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, class_weight='balanced')\n",
    "\n",
    "# 7. Hu·∫•n luy·ªán m√¥ h√¨nh\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 8. D·ª± ƒëo√°n v·ªõi d·ªØ li·ªáu ki·ªÉm tra\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# 9. ƒê√°nh gi√° m√¥ h√¨nh\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(\"üìä Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "\n",
    "print(\"\\nüìà Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372426b3-7d74-4de8-95c8-39fc17953a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 AVG_score\n",
      "2 Prize\n",
      "3 Character\n",
      "4 Anh\n",
      "5 Ho√°\n",
      "6 H√≥a\n",
      "7 L√Ω\n",
      "8 Sinh\n",
      "9 S·ª≠\n",
      "10 To√°n\n",
      "11 VƒÉn\n",
      "12 ƒê·ªãa\n",
      "13 Ch∆°i c·ªù\n",
      "14 Ch∆°i game\n",
      "15 Ch∆°i nh·∫°c c·ª•\n",
      "16 Ch∆°i th·ªÉ thao\n",
      "17 Ch·ª•p ·∫£nh\n",
      "18 C√¥ng ngh·ªá\n",
      "19 Di·ªÖn k·ªãch\n",
      "20 Du l·ªãch\n",
      "21 Kh·∫£o c·ªï\n",
      "22 L√†m v∆∞·ªùn\n",
      "23 L·∫≠p tr√¨nh\n",
      "24 Nghe nh·∫°c\n",
      "25 Nghi√™n c·ª©u\n",
      "26 N·∫•u ƒÉn\n",
      "27 S√°ng t·∫°o\n",
      "28 Th√≠ nghi·ªám\n",
      "29 Th·ªß c√¥ng\n",
      "30 T√¨nh nguy·ªán\n",
      "31 T√≠nh nguy·ªán\n",
      "32 Vi·∫øt blog\n",
      "33 Vi·∫øt l√°ch\n",
      "34 Xem phim\n",
      "35 ƒê·ªçc s√°ch\n",
      "36 An to√†n\n",
      "37 C√¢n b·∫±ng cu·ªôc s·ªëng\n",
      "38 C√¥ng ngh·ªá cao\n",
      "39 C·ªëng hi·∫øn\n",
      "40 Danh v·ªçng\n",
      "41 Kh√°m ph√°\n",
      "42 L√†m ch·ªß\n",
      "43 L∆∞∆°ng cao\n",
      "44 Ph√¢n t√≠ch d·ªØ li·ªáu\n",
      "45 Qu·ªëc t·∫ø h√≥a\n",
      "46 S√°ng t·∫°o\n",
      "47 ThƒÉng ti·∫øn nhanh\n",
      "48 Tr√≠ tu·ªá\n",
      "49 T·ª± do\n",
      "50 ·∫¢nh h∆∞·ªüng x√£ h·ªôi\n",
      "51 ·ªîn ƒë·ªãnh\n"
     ]
    }
   ],
   "source": [
    "for i, col in enumerate(X.columns, start=1):\n",
    "    print(i, col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21038bf2-d9cf-40f0-9f4a-9d399e383387",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def raw_to_X_test(df_raw, X_columns):\n",
    "    X_test = pd.DataFrame(0, index=df_raw.index, columns=X_columns)\n",
    "\n",
    "    # Numeric\n",
    "    if 'AVG_score' in X_columns:\n",
    "        X_test['AVG_score'] = df_raw['AVG_score']\n",
    "\n",
    "    # Prize\n",
    "    if 'Prize_Yes' in X_columns:\n",
    "        X_test['Prize_Yes'] = (df_raw['Prize'] == 'Yes').astype(int)\n",
    "\n",
    "    # Character\n",
    "    for idx, char in enumerate(df_raw['Character']):\n",
    "        col_name = f'Character_{char}'\n",
    "        if col_name in X_columns:\n",
    "            X_test.loc[idx, col_name] = 1\n",
    "\n",
    "    # Subjects (Fav_subject_1,2,3)\n",
    "    for i in range(1, 4):\n",
    "        if f'Fav_subject_{i}' in df_raw.columns:\n",
    "            for idx, subj in enumerate(df_raw[f'Fav_subject_{i}']):\n",
    "                col_name = subj\n",
    "                if col_name in X_columns:\n",
    "                    X_test.loc[idx, col_name] = 1\n",
    "\n",
    "    # Hobbies (Hobby_1,2,3)\n",
    "    for i in range(1, 4):\n",
    "        if f'Hobby_{i}' in df_raw.columns:\n",
    "            for idx, hobby in enumerate(df_raw[f'Hobby_{i}']):\n",
    "                col_name = hobby\n",
    "                if col_name in X_columns:\n",
    "                    X_test.loc[idx, col_name] = 1\n",
    "\n",
    "    # Career_trends (Career_trends_1,2,3)\n",
    "    for i in range(1, 4):\n",
    "        if f'Career_trends_{i}' in df_raw.columns:\n",
    "            for idx, ct in enumerate(df_raw[f'Career_trends_{i}']):\n",
    "                col_name = ct\n",
    "                if col_name in X_columns:\n",
    "                    X_test.loc[idx, col_name] = 1\n",
    "\n",
    "    return X_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1b1b6795-5aef-4bea-98ad-4c10227400b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AVG_score</th>\n",
       "      <th>Fav_subject_1</th>\n",
       "      <th>Fav_subject_2</th>\n",
       "      <th>Fav_subject_3</th>\n",
       "      <th>Prize</th>\n",
       "      <th>Hobby_1</th>\n",
       "      <th>Hobby_2</th>\n",
       "      <th>Hobby_3</th>\n",
       "      <th>Character</th>\n",
       "      <th>Career_trends_1</th>\n",
       "      <th>Career_trends_2</th>\n",
       "      <th>Career_trends_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.5</td>\n",
       "      <td>To√°n</td>\n",
       "      <td>L√Ω</td>\n",
       "      <td>H√≥a</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Nghi√™n c·ª©u</td>\n",
       "      <td>Xem phim</td>\n",
       "      <td>Nghe nh·∫°c</td>\n",
       "      <td>H∆∞·ªõng n·ªôi</td>\n",
       "      <td>L∆∞∆°ng cao</td>\n",
       "      <td>Kh√°m ph√°</td>\n",
       "      <td>ThƒÉng ti·∫øn nhanh</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AVG_score Fav_subject_1 Fav_subject_2 Fav_subject_3 Prize     Hobby_1  \\\n",
       "0        8.5          To√°n            L√Ω           H√≥a   Yes  Nghi√™n c·ª©u   \n",
       "\n",
       "    Hobby_2    Hobby_3  Character Career_trends_1 Career_trends_2  \\\n",
       "0  Xem phim  Nghe nh·∫°c  H∆∞·ªõng n·ªôi       L∆∞∆°ng cao        Kh√°m ph√°   \n",
       "\n",
       "    Career_trends_3  \n",
       "0  ThƒÉng ti·∫øn nhanh  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    \"AVG_score\": [8.5],\n",
    "    \"Fav_subject_1\": [\"To√°n\"],\n",
    "    \"Fav_subject_2\": [\"L√Ω\"],\n",
    "    \"Fav_subject_3\": [\"H√≥a\"],\n",
    "    \"Prize\": [\"Yes\"],\n",
    "    \"Hobby_1\": [\"Nghi√™n c·ª©u\"],\n",
    "    \"Hobby_2\": [\"Xem phim\"],\n",
    "    \"Hobby_3\": [\"Nghe nh·∫°c\"],\n",
    "    \"Character\": [\"H∆∞·ªõng n·ªôi\"],\n",
    "    \"Career_trends_1\": [\"L∆∞∆°ng cao\"],\n",
    "    \"Career_trends_2\": [\"Kh√°m ph√°\"],\n",
    "    \"Career_trends_3\": [\"ThƒÉng ti·∫øn nhanh\"]\n",
    "}\n",
    "\n",
    "df_test_raw = pd.DataFrame(data)\n",
    "df_test_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f1d6f81-ee3f-49f1-9c6c-77a469fae66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_raw l√† DataFrame d·∫°ng raw c·ªßa b·∫°n\n",
    "X_test = raw_to_X_test(df_test_raw, X.columns)\n",
    "# X_test\n",
    "# # B√¢y gi·ªù X_test c√≥ c√πng c·ªôt v·ªõi X.columns\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5e66b80-c25f-48c3-b28a-8eb67b3d062e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['K·ªπ s∆∞ ph·∫ßn m·ªÅm']\n"
     ]
    }
   ],
   "source": [
    "# Chuy·ªÉn v·ªÅ nh√£n g·ªëc\n",
    "y_pred_labels = le_encoder.inverse_transform(y_pred)\n",
    "\n",
    "print(y_pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "41f1f489-1dfc-4bbf-8739-d7aefac02ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_top5(model, label_encoder, X_test, top_n=5):\n",
    "    # X√°c su·∫•t d·ª± ƒëo√°n\n",
    "    proba = model.predict_proba(X_test)  # shape: (n_samples, n_classes)\n",
    "    \n",
    "    # Nh√£n model s·ª≠ d·ª•ng\n",
    "    classes = model.classes_  # numeric labels (encoded)\n",
    "    \n",
    "    # top 5 nh√£n g·ªëc\n",
    "    top5_list = []\n",
    "\n",
    "    # Nh√£n predict() ch√≠nh x√°c (top 1)\n",
    "    y_pred_top1 = model.predict(X_test)  \n",
    "\n",
    "    for i in range(X_test.shape[0]):\n",
    "        # argsort x√°c su·∫•t gi·∫£m d·∫ßn\n",
    "        sorted_idx = np.argsort(-proba[i])\n",
    "        top_indices = sorted_idx[:top_n]\n",
    "\n",
    "        # ƒë·∫£m b·∫£o top 1 = predict()\n",
    "        top_indices = np.insert(top_indices, 0, np.where(classes == y_pred_top1[i])[0][0])\n",
    "        top_indices = np.unique(top_indices)[:top_n]\n",
    "\n",
    "        # Chuy·ªÉn v·ªÅ nh√£n g·ªëc\n",
    "        top_labels = label_encoder.inverse_transform(classes[top_indices])\n",
    "        top5_list.append(top_labels)\n",
    "\n",
    "    return pd.DataFrame(top5_list, columns=[f'Top{i+1}' for i in range(top_n)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a68a8117-fc89-4b9f-be4f-607abc2644bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  Top1                Top2            Top3               Top4  \\\n",
      "0  C√¥ng ngh·ªá th√¥ng tin  Kinh doanh qu·ªëc t·∫ø  K·ªπ s∆∞ ph·∫ßn m·ªÅm  K·ªπ thu·∫≠t ph·∫ßn m·ªÅm   \n",
      "\n",
      "               Top5  \n",
      "0  Tr√≠ tu·ªá nh√¢n t·∫°o  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# D·ª± ƒëo√°n top 5\n",
    "top5_df = predict_top5(model, le_encoder, X_test, top_n=5)\n",
    "\n",
    "print(top5_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5187b8a-ef81-4dbe-9c48-9d5f659aae8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf_model.pkl']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# gi·∫£ s·ª≠ model l√† RandomForestClassifier ƒë√£ train\n",
    "joblib.dump(model, \"rf_model.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a03a4419-41bb-4bc6-8879-a605b482070f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model_columns.pkl']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# L∆∞u c·ªôt\n",
    "joblib.dump(list(X.columns), \"model_columns.pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6d561aa5-f3fa-4ea1-9cbd-4d250616acfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['label_encoder.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(le_encoder, \"label_encoder.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "51fb878c-3fc9-4533-b1ea-31dce62a0686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape X_train: (600, 51)\n",
      "Shape X_test: (1, 51)\n"
     ]
    }
   ],
   "source": [
    "# gi·∫£ s·ª≠ X l√† DataFrame train c·ªßa b·∫°n\n",
    "X_test = raw_to_X_test(df_test_raw, X.columns)\n",
    "\n",
    "print(\"Shape X_train:\", X.shape)\n",
    "print(\"Shape X_test:\", X_test.shape)\n",
    "\n",
    "# d·ª± ƒëo√°n\n",
    "y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f18dd38-54cc-4e56-9089-13643a6b9d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
